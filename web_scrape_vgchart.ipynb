{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install streamlit pyngrok\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpoK4bNdB4ib",
        "outputId": "6846af95-d1d4-49e2-d5e7-3a62d7d417d5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.42.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.25.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.42.0-py2.py3-none-any.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.42.0 watchdog-6.0.0\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.42.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.25.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.3\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#web scrape"
      ],
      "metadata": {
        "id": "6jogZgW_1-NV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if needed: pip install requests or conda install requests\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import lxml.html as lh\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def find_console_tags(soup):\n",
        "    # Console tags are stored as images, so we find the image tag and record its 'alt' value as text\n",
        "    consoles = list()\n",
        "    for img in soup.find_all('img'):\n",
        "        if 'images/consoles'in img['src']:\n",
        "            # Cut file path elements from string\n",
        "            console_tag = (img['src'][17:-6])\n",
        "            consoles.append(img['alt'])\n",
        "    return consoles\n",
        "\n",
        "\n",
        "# Find the names of games from the links\n",
        "def find_names_column(table_path):\n",
        "    names_list = list()\n",
        "    for row in table_path.xpath('.//tr'):\n",
        "        for td in row.xpath('.//td'):\n",
        "            if not td.find('a') is None:\n",
        "                names_list.append(td.find('a').text.strip())\n",
        "    return names_list\n",
        "\n",
        "# Write a function that takes in a VGChartz URL and gives us all the data in their video game database\n",
        "def scrape_vgchartz_videogame_db_page(url):\n",
        "\n",
        "    response = requests.get(url)\n",
        "\n",
        "    ### Check the Status\n",
        "    assert(response.status_code == 200),\" Website not OK \" # status code = 200 => OK\n",
        "\n",
        "    #Store the contents of the website under doc\n",
        "    page=response.text\n",
        "    soup = BeautifulSoup(page, \"lxml\")\n",
        "    doc = lh.fromstring(response.content)\n",
        "\n",
        "    # Selects the table with all the data in it on HTML using xpath\n",
        "    target_table_path = doc.xpath('//*[@id=\"generalBody\"]/table')[0]\n",
        "\n",
        "    # Find column values that won't be scraped correctly with .text option\n",
        "    names_list = find_names_column(target_table_path)\n",
        "    consoles = find_console_tags(soup)\n",
        "\n",
        "    # Parse non-image and non-URL info from the data table to a pandas DataFrame\n",
        "    row_dict={}\n",
        "    df=pd.DataFrame()\n",
        "    row_list= list()\n",
        "    for counter,row in enumerate(target_table_path.xpath(\".//tr\")):\n",
        "        if counter > 2: # To skip header rows\n",
        "            row_list=[td.text for td in row.xpath(\".//td\")]\n",
        "            row_dict[counter] = row_list\n",
        "\n",
        "    df=pd.DataFrame.from_dict(row_dict).transpose()\n",
        "    df.columns = ['position','game','blank','console','publisher','developer','vgchart_score',\\\n",
        "                 'critic_score','user_score','total_shipped','total_sales',\\\n",
        "                  'na_sales','pal_sales','japan_sales','other_sales',\\\n",
        "                  'release_date','last_update']\n",
        "\n",
        "    # Correct the console and game columns using scraped values\n",
        "\n",
        "    df=df.reset_index().drop(columns = ['index','blank'])\n",
        "    df['console'] = consoles\n",
        "    df['game'] = names_list\n",
        "    return df\n",
        "\n",
        "    # We can 'hack' the URL to display any number of results per page. I'll leave it as an argument.\n",
        "def scrape_all_vg_chartz_videogame_db(results_per_page):\n",
        "    df = pd.DataFrame()\n",
        "    current_page = 1\n",
        "    games_left = True\n",
        "    while games_left:\n",
        "        url = 'http://www.vgchartz.com/games/games.php?page=' + str(current_page) +\\\n",
        "        '&results=' + str(results_per_page) + '&name=&console=&keyword=&publisher=&genre=&order=Sales&ownership\\\n",
        "        =Both&boxart=Both&banner=Both&showdeleted=&region=All&goty_year=&developer=&direction\\\n",
        "        =DESC&showtotalsales=1&shownasales=1&showpalsales=1&showjapansales=1&showothersales=1&\\\n",
        "        showpublisher=1&showdeveloper=1&showreleasedate=1&showlastupdate=1&showvgchartzscore=1&\\\n",
        "        showcriticscore=1&showuserscore=1&showshipped=1&alphasort=&showmultiplat=No'\n",
        "        new_df = scrape_vgchartz_videogame_db_page(url)\n",
        "        df = pd.concat([df, new_df], ignore_index=True)\n",
        "        #REMOVE LATER, TEST CONDIITON\n",
        "      #  if current_page > 3:\n",
        "       #     games_left = False\n",
        "        print('Scraped page: ',current_page)\n",
        "        if new_df.shape[0] < results_per_page:\n",
        "            games_left = False\n",
        "        current_page +=1\n",
        "    print('Scraping done!')\n",
        "    print('Total rows parsed = ', df.shape[0])\n",
        "    return df.reset_index().drop(columns = 'index')\n",
        "\n",
        "# Run the code to scrape! I did 10,000 rows per page to speed things up.\n",
        "df=scrape_all_vg_chartz_videogame_db(10000)\n",
        "\n",
        "# Compress and store for later!\n",
        "df.to_pickle('./FullVGChartzDatabase.zip',compression = 'zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "erM63lS8P_Fm",
        "outputId": "a448aead-faea-4421-c2a9-d3e76cfb2b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8fe03178261c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m# Run the code to scrape! I did 10,000 rows per page to speed things up.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscrape_all_vg_chartz_videogame_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;31m# Compress and store for later!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-8fe03178261c>\u001b[0m in \u001b[0;36mscrape_all_vg_chartz_videogame_db\u001b[0;34m(results_per_page)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mshowpublisher\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0mshowdeveloper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0mshowreleasedate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0mshowlastupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0mshowvgchartzscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mshowcriticscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0mshowuserscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0mshowshipped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0malphasort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0mshowmultiplat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNo\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mnew_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_vgchartz_videogame_db_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m#REMOVE LATER, TEST CONDIITON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-8fe03178261c>\u001b[0m in \u001b[0;36mscrape_vgchartz_videogame_db_page\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscrape_vgchartz_videogame_db_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m### Check the Status\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0;31m# Redirect resolving generator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_redirects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0;31m# Redirect resolving generator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_redirects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mresolve_redirects\u001b[0;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m                 resp = self.send(\n\u001b[0m\u001b[1;32m    266\u001b[0m                     \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                     \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mcontent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \"\"\"\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_chunk_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1139\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb\";\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1312\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the pickle file\n",
        "df = pd.read_pickle('./FullVGChartzDatabase.zip', compression='zip')\n",
        "\n",
        "# Convert to CSV\n",
        "df.to_csv('VGChartzDatabase.csv', index=False)"
      ],
      "metadata": {
        "id": "p_aXvPhvSs1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#605"
      ],
      "metadata": {
        "id": "HcRQeV142GoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "oG7DkzWy2UyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vg games the player values are in millions"
      ],
      "metadata": {
        "id": "IasyPtZ2Y1c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vgames=pd.read_csv(\"/content/video_game.csv\")"
      ],
      "metadata": {
        "id": "bHepT99X2XW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GAD     [0 --> 3] [not at all,  several days,  over half the days, nearly always]   (more is bad)\n",
        "\n",
        "#If u feel nervous, anxious\n",
        "#not being able to control or stop worrying\n",
        "#worrying too much about other things\n",
        "#trouble relaxing\n",
        "#being restless\n",
        "#becoming easily annoyd or irritated\n",
        "#feeling awfull as somthin bad is goin to happen\n",
        "\n",
        "#GADE  - If u checked any off these problems,\n",
        "#how difficult these made it for you to do your work, take care of things at home, or get along with people\n",
        "\n"
      ],
      "metadata": {
        "id": "K4MXK9OG7jY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SWL    [1 --> 7] [Strongly disagree, Disagree, silghtly disagree, neutral, silghtly agre, agree, strongly disagree]  (more is good)\n",
        "\n",
        "#satisfied\n",
        "#ideal\n",
        "#excellent life\n",
        "#wont not change my life\n",
        "#gotten important things in I want in my life"
      ],
      "metadata": {
        "id": "vNOnUfgb81t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#narc [1 - 5]   from not true - very true"
      ],
      "metadata": {
        "id": "d4JJNiGY938M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/GamingStudy_data.csv\", encoding='latin-1')\n",
        "df_clean = df.dropna(subset=[\"Hours\"])\n",
        "numeric_df = df_clean.select_dtypes(include=['number'])\n",
        "correlations = numeric_df.corr()[\"Hours\"].drop(\"Hours\").sort_values(ascending=False)\n",
        "# print(correlations)\n",
        "\n",
        "df = pd.read_csv(\"/content/GamingStudy_data.csv\", encoding='latin-1')\n",
        "df_clean = df.dropna(subset=[\"Narcissism\"])\n",
        "numeric_df = df_clean.select_dtypes(include=['number'])\n",
        "correlations = numeric_df.corr()[\"Narcissism\"].drop(\"Narcissism\").sort_values(ascending=False)\n",
        "#print(correlations)\n",
        "\n",
        "df = pd.read_csv(\"/content/GamingStudy_data.csv\", encoding='latin-1')\n",
        "df_clean = df.dropna(subset=[\"streams\"])\n",
        "numeric_df = df_clean.select_dtypes(include=['number'])\n",
        "correlations = numeric_df.corr()[\"streams\"].drop(\"streams\").sort_values(ascending=False)\n",
        "# print(correlations)"
      ],
      "metadata": {
        "id": "TwxFSJC8hidH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Features for regression imputation\n",
        "features = [\"Hours\", \"SPIN_T\"]\n",
        "\n",
        "# Drop rows where target (Hours) and features are missing\n",
        "df_filtered = df.dropna(subset=[\"streams\"] + features)\n",
        "\n",
        "# Define training data\n",
        "X_train = df_filtered[features]\n",
        "y_train = df_filtered[\"streams\"]\n",
        "\n",
        "# Choose imputation strategy based on skewness\n",
        "imputation_strategy = 'mean' if X_train[features].skew().abs().max() < 1 else 'median'\n",
        "\n",
        "# Create a pipeline with imputation and regression\n",
        "pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy=imputation_strategy)),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# Fit the pipeline\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Select rows where \"Hours\" is missing\n",
        "missing_stream = df[df[\"streams\"].isnull()].copy()\n",
        "\n",
        "# Check if there are missing values before predicting\n",
        "if missing_stream.empty:\n",
        "    print(\"No missing values in 'streams' column to impute.\")\n",
        "else:\n",
        "    # Predict missing values\n",
        "    df.loc[df[\"streams\"].isnull(), \"streams\"] = np.round(pipeline.predict(missing_stream[features]))\n",
        "    print(\"Missing 'streams' values imputed and updated in df.\")\n",
        "    #print(df.loc[missing_stream.index, [\"streams\"]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41kTlZ1ns-Lc",
        "outputId": "f296ffdc-0e1c-4ad4-eb16-c17f2907427e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing 'streams' values imputed and updated in df.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Features for regression imputation\n",
        "features = [\"GAD6\", \"GAD_T\",\"GAD5\"]\n",
        "\n",
        "# Drop rows where target (Hours) and features are missing\n",
        "df_filtered = df.dropna(subset=[\"Narcissism\"] + features)\n",
        "\n",
        "# Define training data\n",
        "X_train = df_filtered[features]\n",
        "y_train = df_filtered[\"Narcissism\"]\n",
        "\n",
        "# Choose imputation strategy based on skewness\n",
        "imputation_strategy = 'mean' if X_train[features].skew().abs().max() < 1 else 'median'\n",
        "\n",
        "# Create a pipeline with imputation and regression\n",
        "pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy=imputation_strategy)),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# Fit the pipeline\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Select rows where \"Hours\" is missing\n",
        "missing_narc = df[df[\"Narcissism\"].isnull()].copy()\n",
        "\n",
        "# Check if there are missing values before predicting\n",
        "if missing_narc.empty:\n",
        "    print(\"No missing values in 'Narcissism' column to impute.\")\n",
        "else:\n",
        "    # Predict missing values\n",
        "    df.loc[df[\"Narcissism\"].isnull(), \"Narcissism\"] = np.round(pipeline.predict(missing_narc[features]))\n",
        "    print(\"Missing 'Narcissism' values imputed and updated in df.\")\n",
        "    #print(df.loc[missing_narc.index, [\"Narcissism\"]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvFB4hNPhRq9",
        "outputId": "0d89a418-ab06-46ba-e91d-c9b967e6db5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing 'Narcissism' values imputed and updated in df.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Features for regression imputation\n",
        "features = [\"streams\", \"SPIN_T\", \"SPIN13\", \"SPIN16\", \"SPIN12\",\n",
        "            \"Narcissism\", \"SPIN8\", \"SPIN10\", \"SPIN3\", \"SPIN14\"]\n",
        "\n",
        "# Drop rows where target (Hours) and features are missing\n",
        "df_filtered = df.dropna(subset=[\"Hours\"] + features)\n",
        "\n",
        "# Define training data\n",
        "X_train = df_filtered[features]\n",
        "y_train = df_filtered[\"Hours\"]\n",
        "\n",
        "# Choose imputation strategy based on skewness\n",
        "imputation_strategy = 'mean' if X_train[features].skew().abs().max() < 1 else 'median'\n",
        "\n",
        "# Create a pipeline with imputation and regression\n",
        "pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy=imputation_strategy)),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# Fit the pipeline\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Select rows where \"Hours\" is missing\n",
        "missing_hours = df[df[\"Hours\"].isnull()].copy()\n",
        "\n",
        "# Check if there are missing values before predicting\n",
        "if missing_hours.empty:\n",
        "    print(\"No missing values in 'Hours' column to impute.\")\n",
        "else:\n",
        "    # Predict missing values\n",
        "    df.loc[df[\"Hours\"].isnull(), \"Hours\"] = pipeline.predict(missing_hours[features])\n",
        "    print(\"Missing 'Hours' values imputed and updated in df.\")\n",
        "    #print(df.loc[missing_hours.index, [\"Hours\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH6z_Uh5qrEs",
        "outputId": "d0af1971-fdc6-4112-f2ca-236b0ddf1ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing 'Hours' values imputed and updated in df.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s_drop = ['Unnamed: 0', 'Zeitstempel','Birthplace_ISO3','Residence_ISO3', 'highestleague',\n",
        "          'GAD1','GAD2','GAD3','GAD4','GAD5','GAD6','GAD7','SWL1','SWL2','SWL3','SWL4','SWL5',\n",
        "          'SPIN1','SPIN2','SPIN3','SPIN4','SPIN5','SPIN6','SPIN7','SPIN8','SPIN9','SPIN10','SPIN11',\n",
        "          'SPIN12','SPIN13','SPIN14','SPIN15','SPIN16','SPIN17','SPIN_T','accept']\n",
        "sgames = df.drop(columns=s_drop)\n",
        "\n"
      ],
      "metadata": {
        "id": "iDthbDTG3dJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgames['whyplay'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN1_rZYxxIf6",
        "outputId": "bab23c68-bf72-4cdb-ee70-cbc5589b488a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['having fun', 'improving', 'relaxing', 'winning',\n",
              "       'improving, having fun', 'All',\n",
              "       \"I play it as I watch TV or movies.  I've gone through many a Netflix binge with Isaac.\",\n",
              "       'Reaching goal i.e. GM ',\n",
              "       'Improving AND having fun (kinda wish I could pick more than one)',\n",
              "       'all of the above', 'passing the time', 'having fun and improving',\n",
              "       'Forgetting troubles', 'All of them', 'Being with friends',\n",
              "       'getting good loot', 'have fun and win',\n",
              "       'Winning 55% improving 45%', 'Wasting time',\n",
              "       'talking to irl friends', 'Forgetting about my drug addiction',\n",
              "       'Having fun and improving at the same time',\n",
              "       'Improving and having fun.', 'improving while having fun',\n",
              "       'All of the above!', 'socializing', 'all above', 'playing well',\n",
              "       'winning + having fun', 'having a distraction',\n",
              "       'the three last: improving, relaxing and having fun',\n",
              "       'winning and improving',\n",
              "       'depends, wwinning in rankeds, fun and relaxing in normal / aram',\n",
              "       'winning whilst improving', 'All four of the above.',\n",
              "       'Relaxing & having fun', 'improving & having fun',\n",
              "       \"Having fun and winning (or at least trying to win, I dislike playing without the goal of winning.) You play a game to win, which doesnt mean you can't have fun :) Doesnt mean losing cant be fun tho. \",\n",
              "       'All of the above.', 'All 4 things at different times.',\n",
              "       'All of the above',\n",
              "       'winning because if i lose while boosting i wont get money ',\n",
              "       'passing time', 'not thinking about my clinic depression.',\n",
              "       'all answers mentioned', 'All of the above ',\n",
              "       'Winning is the most fun but I sometimes still have fun if I loose',\n",
              "       'all of the above depending on mood; to distract myself',\n",
              "       'winning is fun and relaxing',\n",
              "       'fulfilling a concept that you created based on the resources that are given to you by the game',\n",
              "       'conpeting, the fun that comes with it', 'mental stimulation',\n",
              "       'All of these 4', 'Not beeing bored',\n",
              "       'spend time with my best friend(s)',\n",
              "       'spending time with special person', 'Not getting bored.',\n",
              "       'relaxing+having fun', 'Everything from the list',\n",
              "       'Improving and having fun', 'Winning & having fun',\n",
              "       \"Distracting myself from the multiple disorders I have on bad days while on good days I don't play as much.\",\n",
              "       'All 4 above',\n",
              "       \"winning and improving, it's stoped being about fun a long time ago, but fun is still there\",\n",
              "       'Equally value winning and having fun',\n",
              "       'all of the above minus relaxing', 'a good challenge',\n",
              "       'improving or having fun, depending whether or not I am playing with friends or not',\n",
              "       'all from above',\n",
              "       'combination of all above, mostly improving and winning',\n",
              "       'both, improving and having fun', 'having fun while winning',\n",
              "       'winning while having fun', 'Depends on the day',\n",
              "       'All of those are goals and their importance varies.',\n",
              "       'Improving and relaxing too',\n",
              "       'having fun and winning (its part of having fun for me)',\n",
              "       'Winning is funner', 'Winning AND Improving',\n",
              "       'destroying the enemy', 'First two options',\n",
              "       'haivng fun and winning equally important',\n",
              "       'A little bit of both to be honest. I play because its fun, but I prefer winning over losing obviously.',\n",
              "       'depends on my mood. sometimes winning and improving, sometimes just to relax',\n",
              "       'both relaxing and having fun', 'Being better than my friends',\n",
              "       'I mostly play out of habit.', 'forgetting',\n",
              "       'Working together for an objective, stopping people abusing each others',\n",
              "       'Performing', 'With friends having fun, alone improving',\n",
              "       'Improving and Having fun', 'Winning and having fun ',\n",
              "       'Both winning and having fun', 'playing with friends',\n",
              "       'all of those, but i guess everyone wants to win...',\n",
              "       'All of the above :)', 'The last 3 Choices', 'having fun=winning',\n",
              "       'All of the above. ', 'Winning/Improving/Having Fun',\n",
              "       \"winning is having fun. I can't choose between the two.\",\n",
              "       'Winning, Relax and trying to learn meanwhile ',\n",
              "       'Working as a team', 'both improving and relaxing',\n",
              "       \"All are important, I can only have fun and relax if I'm trying my best to win and improve\",\n",
              "       'improving AND relaxing', 'having fun, winning and also improving',\n",
              "       'all of the above ', 'fun and relaxing',\n",
              "       'improving, having fun, relaxing', 'having fun but still winning ',\n",
              "       'Having fun while winning.', 'winning and having fun 50/50',\n",
              "       'Habit', 'Everything from above',\n",
              "       'Relaxing without improving or the other way rounds is a waste for me, so both.',\n",
              "       'A combination of fun (with friends,) and improving (in competitive)',\n",
              "       'not having retarded teammates',\n",
              "       'just wasting time as i have nothing else to do in life',\n",
              "       'Having fun and Improving', 'competeing',\n",
              "       'having fun and winning is not bad either', 'All Above',\n",
              "       'Haveing fun and relaxing', 'all the above',\n",
              "       'its a little of everything listed', 'metting new people',\n",
              "       'distraction', 'Distraction', 'killing time', 'satisfaction',\n",
              "       'Improving/ Having fun equal', 'time with friends',\n",
              "       'Having fun, expecially when winning', 'I have no idea',\n",
              "       'depends what im playing.',\n",
              "       'Both improving and having fun are equally important to me.',\n",
              "       'it just works as a distraction. other then that winning and climbing that ladder',\n",
              "       'Improving, having fun & winning', 'to be occupied',\n",
              "       'Improving + Fun', 'improving and having fun',\n",
              "       'Combination: Winning / Having fun', 'Having fun and improving',\n",
              "       'Making my brain go numb', 'All of above',\n",
              "       'Improving, relaxing and having fun are equally important to me and tied so close, that they cannot exist without each other (e.g. I can only have fun while relaxing and I always try to improve while relaxing and having fun),',\n",
              "       'occupation', 'Not feeling the pain my mind can inflict on me',\n",
              "       'i have fun when i see myself getting better at the game',\n",
              "       'Winning while having fun', 'Both having fun and improving.',\n",
              "       'All of the above with an emphasis on winning.',\n",
              "       'individual performance and winning together',\n",
              "       'Improving while having fun', 'dumpster the enemy beyond words',\n",
              "       'competitive play, improving but in games that are winnable',\n",
              "       'Myself doing well (KDA)',\n",
              "       \"Winning and having fun, I'm a sporty person so I'm competitive.\",\n",
              "       'Winning improving relaxing having fun',\n",
              "       \"can't emphasize winning enough\",\n",
              "       'Getting to the top of the boards', 'winning/having fun',\n",
              "       '1. Having fun 2. winning 3. improving 4. relaxing (all in a bit)',\n",
              "       'Having fun and improving 50/50', 'having fun with friends',\n",
              "       'improving, relaxing, and having fun.',\n",
              "       'Combination of having fun, relaxing and improving',\n",
              "       'being better than the majority', 'playing the game',\n",
              "       'learning how the game works and compare to other games',\n",
              "       'both winning and improving, one brings the other',\n",
              "       'All of them, winning is fun, improving is rewarding.',\n",
              "       'improving and watching myself getting higher on ladder',\n",
              "       'depends on the match type. but having fun and improving means alot ',\n",
              "       'winning is fun but can have fun games without winning',\n",
              "       'Performing well', 'cooperating', 'Little of everything.',\n",
              "       'Depends on the mindset. Who am I playing with? It might be winning if I feel like being competitive, or just having fun.',\n",
              "       'improving, relaxing and having fun', 'Improving and winning',\n",
              "       'improving + having fun', 'mix between winning and improving ',\n",
              "       'A mix of everything listed', 'forgetting about the reality',\n",
              "       'Killing time.', 'Teamwork',\n",
              "       'Having fun is the reason we all start to play a game.',\n",
              "       \"A combination of winning, improving, and having fun.  I don't regret playing if we don't win or make mistakes.\",\n",
              "       'A mix of the 4 above', 'All of the above are equal to me',\n",
              "       'sometimes winning; sometimes having fun',\n",
              "       'having fun and winning equally important, willing to lose if having fun...etc',\n",
              "       'All, depends on mood', 'winning, improving and having fun',\n",
              "       'improving and winning', 'having fun, but winning is fun',\n",
              "       'all of the above. I play league to relax and destress, but also to improve as I enter tournaments from time to time :)',\n",
              "       'Stimulate Cognition and logic thinking, relax/have fun',\n",
              "       \"All of the above - losing isn't fun, but you can still learn to improve\",\n",
              "       'Getting better at the game.', 'to pass time',\n",
              "       'Any of the former depending on the day.', 'competition',\n",
              "       'Crushing kids ', 'Having fun together WITH friends',\n",
              "       'in ranked, winning, in normal draft improving, in normal blind having fun',\n",
              "       'All of them :)', 'All of the above when playing LoL',\n",
              "       'all of above', 'having fun<improving<winning<relaxing',\n",
              "       'winning+improving',\n",
              "       'All of the above, alternating based on mood.',\n",
              "       'A mix of the last three',\n",
              "       'all of the above are equally important',\n",
              "       'having fun, improving and winning =)',\n",
              "       'having fun & passing time',\n",
              "       'both improving and having fun equally important',\n",
              "       'Winning and having fun',\n",
              "       \"It depends whether I'm playing ranked (improving/winning) or normals (having fun/relaxing)\",\n",
              "       'Alternates between improving and having fun', 'learning',\n",
              "       'a mixture of improving, relaxing, and having fun',\n",
              "       'relaxing and having fun', 'fun is winning, so winning',\n",
              "       'Winning and improving. Both.',\n",
              "       'Having fun, but to enjoy competetive games you must be good. Therefore improving as well. ',\n",
              "       'content way to waste time',\n",
              "       'Doing well (not bringing my team down)',\n",
              "       'depends, winning or having fun', 'All of them really',\n",
              "       'having fun and then winning', 'winning and relaxing',\n",
              "       'Relaxing and having fun', 'Time with friends', 'Sexual thrill',\n",
              "       'having fun by giving it your best shot.',\n",
              "       'All but relaxing, but mostly fun', 'having fun by improving',\n",
              "       'metagame', 'Both Improving and having fun',\n",
              "       'Mix of improving and having fun. ', 'improving,relaxing',\n",
              "       'Improving but also having fun :)',\n",
              "       'All of these are equally important to me except relaxing.',\n",
              "       \"ranked, winning/ improving, currently it's winning, but i need to change my mindset to improving\",\n",
              "       'chasing singed and killing Teemo',\n",
              "       'learning, having fun and relaxing',\n",
              "       'hide from my real world problems', 'Escaping',\n",
              "       \"I Have no idea why I'm playing.\", 'Having fun and winning',\n",
              "       'trying to get my mind off',\n",
              "       'while winning, but loss is not a problem',\n",
              "       'depends from Time to time ( between winning, improving, and having fun)',\n",
              "       \"When I'm playing for money - winning. When I'm playing on my own/with friends - it's for fun.\",\n",
              "       'All of the above. Winning, improving, relaxing, and having fun.',\n",
              "       'helping others', 'a combination of all',\n",
              "       'Both having fun and relaxing', 'A, B, and D', 'Learning',\n",
              "       'time sink (just something to do)', 'They all contribute equally',\n",
              "       'to kill time', 'Improving/Having Fun/Teaching others',\n",
              "       'A mix of everything',\n",
              "       'improving when playing alone, having fun with friends',\n",
              "       'Winning, Improving, and having fun', 'having something to do',\n",
              "       'Having fun, but who plays to lose? ;)', 'Social need',\n",
              "       'All the above', \"Feeling like I'm playing my role well\",\n",
              "       'getting away from real life', 'Winning AND having fun!',\n",
              "       'winning and having interesting plays',\n",
              "       'depends on game mode (ranked obviously winning, else for fun)',\n",
              "       'Improving, having fun and relaxing. ', 'backdooring in ARAMs',\n",
              "       'Keeping my mind off my shortcomings.',\n",
              "       'Improvement and enjoyment',\n",
              "       'having fun in some and winning in some ', 'Winning or having fun',\n",
              "       'all of the above, depending on the days',\n",
              "       \"I'm competetive minded - improving/winning \", 'all of them',\n",
              "       'my ear is happy', 'Improving + Having fun',\n",
              "       'it depends, little bit of everything',\n",
              "       \"Relaxing, having fun and improving. Winning isn't always important but it's nice.\",\n",
              "       'improving mostly, but having fun as well', 'play with friends',\n",
              "       'Competition',\n",
              "       'Well.. Relaxing and having fun but also improving :D',\n",
              "       'Feeling that I performed well', 'a mix of all 4 points',\n",
              "       'depends, if playing with friends having fun otherways winning',\n",
              "       'Winning and Having Fun', 'Winning and improving',\n",
              "       'depending of mood, mostly winning, but sometimes I want to relax and have fun and I always want to improve',\n",
              "       'A mix of having fun and improving', 'Taking focus off of work',\n",
              "       'loot', 'both improving and having fun',\n",
              "       'Depends on what I am playing.',\n",
              "       'I wish it was having fun, but unfortunately its winning',\n",
              "       'being satisfied with my skill',\n",
              "       'winning/improving/and having fun',\n",
              "       'mix between having fun and improving',\n",
              "       'winning and improving at the same time having fun',\n",
              "       'playing with friends and winning with them as a team',\n",
              "       'winning and fun evenly', 'combination of all above',\n",
              "       'procrastinating', 'having fun can be relaxing',\n",
              "       'having fun and winning',\n",
              "       'A mix between fun, improviment and winning',\n",
              "       'Challenging my brain and having fun while improving',\n",
              "       'Making it my living',\n",
              "       'Playing my best and having competent teammates',\n",
              "       'Both winning and improving quite equally',\n",
              "       'It varies, i like a mix of all. ', 'Having a new experience',\n",
              "       'fun doing my best and wining isnt bad',\n",
              "       \"If it's not fun, I won't do it, however I want to get good at League because it can be challenging to get good at, it's something to work on in life and it's extremely fun so why the fuck not!\",\n",
              "       'based on which gamemode. If ranked then winning and improving. If with friends then having fun.',\n",
              "       'winning and improving,i have fun doing this.',\n",
              "       'improving means winning means having fun', 'The 4 of them',\n",
              "       \"I don't know anymore\",\n",
              "       'Improving, having fun, and teaching my friends',\n",
              "       'not arguing, focusing on gameplay', 'competing',\n",
              "       'Winning with friends, winning while alone is almost depressing.',\n",
              "       'The KDA!', 'All equally important  ', 'Keeping myself occupied',\n",
              "       'Improving & having fun are equally important to me.',\n",
              "       'winning, while having fun',\n",
              "       'Combination of winning, improving and having fun',\n",
              "       'Learning the game', 'winning while improving',\n",
              "       'Learning/Strategizing',\n",
              "       'Passing time/Distracting myself from worrying',\n",
              "       'improving / tryin to relax',\n",
              "       'Multiplayer: winning. Single player: fun/ experiencing a great story',\n",
              "       'Prove', 'nothing, I just play because people ask me to',\n",
              "       'not losing my time and improve',\n",
              "       'Depends on the time, sometimes I just want to win, other times I just want to have fun.',\n",
              "       'Winning and improving at the same time', 'win and improve',\n",
              "       'Having fun by spending time with my friends :D',\n",
              "       'winning AND improving', 'winning/having fun/relaxing',\n",
              "       \"If I'm playing with friends, it's about having fun. If I'm playing by myself, its about relaxing.\",\n",
              "       'all together', 'doing something', 'overcoming boredom',\n",
              "       'a b c and d',\n",
              "       'improving AND winning are equally important to be honest. so...',\n",
              "       \"winning, but only when it's earned through effort\",\n",
              "       'having fun and improving are equalimy important tho',\n",
              "       'distracting myself', 'all of the above on different days',\n",
              "       'escaping',\n",
              "       'because im not able to check 2, Improving and having fun.',\n",
              "       'the other team losing', 'Playing well ',\n",
              "       'Shitting on the sea anemones',\n",
              "       'improving OR having fun depending on friend group',\n",
              "       'combination of having fun and wining', 'Orgasms',\n",
              "       'Having fun while improving', 'Playing the game',\n",
              "       'Winning while having fun his by far the best thing',\n",
              "       'winning, improving AND having fun', 'Both improving and relaxing',\n",
              "       'Winning + Improving', 'Improving & Winning',\n",
              "       'Winning and improving.', 'Escaping reality', 'Winning/improving ',\n",
              "       'winning helps with fun', 'None of the above framed responses.',\n",
              "       'I play to win while still trying to have fun and not let losing bother me. Improving is probably what I look forward to most, as the skill gap is enormous.',\n",
              "       'both winning and improving ', 'getting better so i can win more ',\n",
              "       'Ranked = winning Normals = Fun', 'Having fun and Improving (:',\n",
              "       'Doing well', 'The people I play with, the game is less important',\n",
              "       'All of The Above', 'some kind of improving and having fun',\n",
              "       \"Making me forget about stuff that's making me nervous\",\n",
              "       'releasing stress/tension', 'playing good',\n",
              "       'All four depending on the nature of the game (ranked, normals, aram, etc)',\n",
              "       'improve to find a team and win',\n",
              "       'All the options are equally important',\n",
              "       'Winning and improving - equally',\n",
              "       'Winning and improving, i have fun when succeeding and i have learned to value losing.',\n",
              "       'Improving AND having fun, while trying to not get stressed.',\n",
              "       'Mental priority is Fun>Improve>Win, actual priority once in game Win>Improve>Fun'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install streamlit pyngrok\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiHSPyCfZy-Z",
        "outputId": "bfc4bae2-506d-4e67-90be-acb3e2b883e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.42.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.25.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.42.0-py2.py3-none-any.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.42.0 watchdog-6.0.0\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.42.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.25.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.3\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#steramtest"
      ],
      "metadata": {
        "id": "1cKAZtQ-nCTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# Title for your app\n",
        "st.title(\"Video Game Sales Analysis\")\n",
        "\n",
        "# Load your dataset\n",
        "# For demonstration, let's create a small DataFrame similar to your dataset.\n",
        "data = {\n",
        "    \"Name\": [\"Wii Sports\", \"Super Mario Bros.\", \"Mario Kart Wii\", \"Wii Sports Resort\"],\n",
        "    \"Year_of_Release\": [2006, 1985, 2008, 2009],\n",
        "    \"Global_players\": [82.53, 40.24, 35.52, 32.77],\n",
        "    \"Genre\": [\"Sports\", \"Platform\", \"Racing\", \"Sports\"]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the DataFrame in your app\n",
        "st.subheader(\"Dataset Preview\")\n",
        "st.write(df)\n",
        "\n",
        "# Create an interactive Plotly scatter plot\n",
        "fig = px.scatter(\n",
        "    df,\n",
        "    x=\"Year_of_Release\",\n",
        "    y=\"Global_players\",\n",
        "    size=\"Global_players\",\n",
        "    color=\"Genre\",\n",
        "    hover_name=\"Name\",\n",
        "    title=\"Global Players vs. Year of Release\"\n",
        ")\n",
        "\n",
        "# Display the plot\n",
        "st.plotly_chart(fig)\n",
        "\n",
        "# Add some interactivity: a slider to filter by year\n",
        "year_range = st.slider(\n",
        "    \"Select Year Range\",\n",
        "    min_value=int(df[\"Year_of_Release\"].min()),\n",
        "    max_value=int(df[\"Year_of_Release\"].max()),\n",
        "    value=(int(df[\"Year_of_Release\"].min()), int(df[\"Year_of_Release\"].max()))\n",
        ")\n",
        "\n",
        "# Filter data based on the slider\n",
        "filtered_df = df[(df[\"Year_of_Release\"] >= year_range[0]) & (df[\"Year_of_Release\"] <= year_range[1])]\n",
        "\n",
        "# Update plot based on filtered data\n",
        "st.subheader(\"Filtered Data\")\n",
        "st.write(filtered_df)\n",
        "\n",
        "fig_filtered = px.scatter(\n",
        "    filtered_df,\n",
        "    x=\"Year_of_Release\",\n",
        "    y=\"Global_players\",\n",
        "    size=\"Global_players\",\n",
        "    color=\"Genre\",\n",
        "    hover_name=\"Name\",\n",
        "    title=f\"Global Players vs. Year of Release (Years {year_range[0]} to {year_range[1]})\"\n",
        ")\n",
        "st.plotly_chart(fig_filtered)\n"
      ],
      "metadata": {
        "id": "GdX2V1ZNZxpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "gLD3Bmf9bJgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.set_auth_token(\"2Z2OwWheOVA9BCe2FBstfdc9NTt_3FnAyeXY2cqFZ3x54WeAv\")"
      ],
      "metadata": {
        "id": "V5D0uJ-Cd6gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup streamlit run app.py &"
      ],
      "metadata": {
        "id": "iw1CzGDqbSY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "public_url = ngrok.connect(8501)\n",
        "print(public_url)"
      ],
      "metadata": {
        "id": "yRBVODRhbWc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# games_pcy"
      ],
      "metadata": {
        "id": "81jKpFo7ffua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "import plotly.express as px\n",
        "from sklearn.impute import KNNImputer\n",
        "import nltk\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from scipy.stats import chi2_contingency, f_oneway\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "\n",
        "# Cache data loading for better performance\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    return pd.read_csv(\"/content/GamingStudy_data.csv\", encoding='latin-1')\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Enhanced categorization with priority system\n",
        "categories = {\n",
        "    'Distraction': ['distract', 'escape', 'forget', 'stress', 'anxiety', 'avoid',\n",
        "                    'reality', 'pain', 'trouble', 'problem', 'depression', 'nervous'],\n",
        "    'Habit/Time Pass': ['habit', 'time', 'pass', 'bored', 'routine', 'kill time',\n",
        "                        'occupied', 'waste', 'fill', 'nothing', 'procrastinate'],\n",
        "    'Social': ['friend', 'team', 'coop', 'multiplayer', 'social', 'together',\n",
        "               'community', 'connect', 'bond', 'relationship', 'with others', 'family'],\n",
        "    'Compete/Win': ['win', 'compete', 'victory', 'rank', 'ladder', 'gm', 'climb',\n",
        "                    'top', 'leaderboard', 'dominate', 'triumph', 'beat', 'champion'],\n",
        "    'Improve/Skill': ['improve', 'learn', 'skill', 'progress', 'master', 'practice',\n",
        "                      'better', 'develop', 'growth', 'hone', 'enhance', 'advance'],\n",
        "    'Fun/Relax': ['fun', 'relax', 'enjoy', 'chill', 'unwind', 'distress', 'joy',\n",
        "                  'pleasure', 'entertain', 'distraction', 'happiness']\n",
        "}\n",
        "category_priority = ['Distraction', 'Habit/Time Pass', 'Social',\n",
        "                    'Compete/Win', 'Improve/Skill', 'Fun/Relax']\n",
        "\n",
        "def categorize_whyplay(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', str(text).lower())\n",
        "    tokens = text.split()\n",
        "    verb_tokens = [WordNetLemmatizer().lemmatize(word, pos='v') for word in tokens]\n",
        "    combined_tokens = set(tokens) | set(verb_tokens)\n",
        "\n",
        "    matched = []\n",
        "    for category in category_priority:\n",
        "        keywords = categories[category]\n",
        "        for keyword in keywords:\n",
        "            if any(keyword in token for token in combined_tokens):\n",
        "                matched.append(category)\n",
        "                break  # Move to next category after first match\n",
        "\n",
        "    if 'all' in combined_tokens or 'every' in combined_tokens:\n",
        "        return category_priority\n",
        "    return matched if matched else ['Other']\n",
        "\n",
        "# Load and process data\n",
        "df = load_data()\n",
        "df['whyplay_cats'] = df['whyplay'].apply(categorize_whyplay)\n",
        "df_exploded = df.explode('whyplay_cats')\n",
        "\n",
        "st.title(\"Data Story on Gaming 🎮\")\n",
        "\n",
        "# Streamlit app\n",
        "\n",
        "tab0, tab1, tab2, tab3, tab4 = st.tabs([\n",
        "    \"📝 Introduction\",\n",
        "    \"🌟 Reason vs Gender\",\n",
        "    \"🌍 Addiction and Satisfaction\",\n",
        "    \"📊 Math behind Games\",\n",
        "    \"🎮 Game Clusters\"\n",
        "])\n",
        "\n",
        "with tab0:\n",
        "    st.subheader(\"A DATA 605 Project by Lalith and Ojas\")\n",
        "    st.subheader(\"Why Gaming ??!!\")\n",
        "    st.markdown(\"\"\"\n",
        "    Did you know that the biggest industry in terms of revenue isn’t movies or music? Surprisingly,\n",
        "    it’s the video gaming industry, which generated a staggering 💲187 billion in 2023. In comparison,\n",
        "    the movie industry brought in 💲133 billion, while the music industry trailed far behind at 💲28 billion.\n",
        "    That means video games earn more than both industries combined.With such immense growth and potential,\n",
        "    it's clear that the video game industry is a gold mine worth exploring.\n",
        "    \"\"\")\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "\n",
        "    1. Gaming Industry\n",
        "-\t2022: $184 billion (Newzoo)\n",
        " Driven by mobile, console, and PC gaming, with strong growth in emerging markets.\n",
        "-\t2023: $187 billion (estimated)\n",
        "\tModerate growth due to post-pandemic normalization and mobile dominance.\n",
        "-\t2024: $200 billion (projected)\n",
        "\tExpected growth from cloud gaming, esports, and next-gen hardware.\n",
        "________________________________________\n",
        "2. Music Industry\n",
        "-\t2022: $26.2 billion (IFPI)\n",
        "\tStreaming accounted for 67% of recorded music revenue.\n",
        "-\t2023: $28–29 billion (estimated)\n",
        "\tContinued growth in streaming and live events post-pandemic.\n",
        "-\t2024: $31–33 billion (projected)\n",
        "\tExpansion in emerging markets and vinyl/cassette nostalgia trends.\n",
        "________________________________________\n",
        "3. Movie Industry\n",
        "-\t2022:\tTheatrical: \\$26 billion (Global Box Office)\n",
        "\tTotal (including streaming): $90 billion (MPA estimates).\n",
        "-\t2023:\tTheatrical: \\$33 billion (Box Office Mojo)\n",
        "\tTotal: $100 billion (streaming platforms like Netflix and Disney+).\n",
        "-\t2024: $105–110 billion (projected)\n",
        "\tHybrid releases (theatrical + streaming) and international markets driving growth.\n",
        "________________________________________\n",
        "4. Sports Industry\n",
        "-\t2022: $487 billion (Statista)\n",
        "\tIncludes media rights, sponsorships, merchandise, and live events.\n",
        "-\t2023: $500–520 billion (estimated)\n",
        "\tRecovery in live attendance and rising media deals (e.g., NFL, Premier League).\n",
        "-\t2024: $550–600 billion (projected)\n",
        "\tGrowth in digital streaming rights and global events (e.g., Olympics, FIFA World Cup)\n",
        "\n",
        "    \"\"\")\n",
        "\n",
        "    st.subheader(\"Info about dataset\")\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    GAD     [0 --> 3]   [not at all,  several days,  over half the days, nearly always]\n",
        "\n",
        "- If u feel nervous, anxious\n",
        "- not being able to control or stop worrying\n",
        "- worrying too much about other things\n",
        "- trouble relaxing\n",
        "- being restless\n",
        "- becoming easily annoyd or irritated\n",
        "- feeling awfull as somthin bad is goin to happen\n",
        "\"\"\")\n",
        "\n",
        "    st.markdown(\"<span style='color: red; font-weight: bold;'>More is Bad!</span>\", unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "\n",
        "SWL    [1 --> 7] [Strongly disagree, Disagree, silghtly disagree, neutral, silghtly agre, agree, strongly disagree]\n",
        "\n",
        "- satisfied\n",
        "- ideal\n",
        "- excellent life\n",
        "- wont not change my life\n",
        "- gotten important things in I want in my life\n",
        " \"\"\")\n",
        "\n",
        "    st.markdown(\"<span style='color: green; font-weight: bold;'>More is Good!</span>\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "with tab1:\n",
        "    st.header(\"Player Motivation Analysis\")\n",
        "\n",
        "    # Create filter buttons in columns\n",
        "    st.subheader(\"Filter Options\")\n",
        "    filter_col1, filter_col2, filter_col3 = st.columns(3)\n",
        "\n",
        "    # Gender Filter\n",
        "    with filter_col1:\n",
        "        gender_options = [\"All\"] + df['Gender'].dropna().unique().tolist()\n",
        "        selected_gender = st.radio(\n",
        "            \"Gender\",\n",
        "            gender_options,\n",
        "            index=0,\n",
        "            key=\"gender_filter\"\n",
        "        )\n",
        "\n",
        "    # Apply filters\n",
        "    filtered_exploded = df_exploded.copy()\n",
        "\n",
        "    if selected_gender != \"All\":\n",
        "        filtered_exploded = filtered_exploded[filtered_exploded['Gender'] == selected_gender]\n",
        "\n",
        "    # Create visualization with filtered data\n",
        "    fig = px.bar(filtered_exploded['whyplay_cats'].value_counts().reset_index(),\n",
        "                x='count', y='whyplay_cats', orientation='h',\n",
        "                title=f\"Gaming Motivations Breakdown\",\n",
        "                labels={'whyplay_cats': 'Motivation Category', 'count': 'Player Count'},\n",
        "                color='whyplay_cats',\n",
        "                color_discrete_sequence=px.colors.qualitative.Pastel)\n",
        "\n",
        "    # Dynamic subtitle with active filters\n",
        "    filter_text = []\n",
        "    if selected_gender != \"All\": filter_text.append(f\"Gender: {selected_gender}\")\n",
        "\n",
        "\n",
        "    if filter_text:\n",
        "        st.caption(f\"Active filters: {', '.join(filter_text)}\")\n",
        "\n",
        "    fig.update_layout(\n",
        "        height=500,\n",
        "        width=800,\n",
        "        yaxis_title=\"Motivation Category\",\n",
        "        xaxis_title=\"Number of Players\",\n",
        "        legend_title=\"Motivation\",\n",
        "        showlegend=False  # Cleaner look for horizontal bars\n",
        "    )\n",
        "\n",
        "    st.plotly_chart(fig)\n",
        "    # Chi-square test for association between Gender and whyplay_cats\n",
        "    st.header(\"Statistical Analysis\")\n",
        "    contingency_table = pd.crosstab(df_exploded['Gender'], df_exploded['whyplay_cats'])\n",
        "    chi2, p, _, _ = chi2_contingency(contingency_table)\n",
        "\n",
        "    st.subheader(\"Chi-Square Test Results\")\n",
        "    st.markdown(f\"\"\"\n",
        "    - **Chi-Square Statistic**: `{chi2:.2f}`\n",
        "    - **P-value**: `{p:.5f}`\n",
        "    - **Significance**: {'✅ Significant' if p < 0.05 else '❌ Not Significant'}\n",
        "    \"\"\")\n",
        "    st.subheader(\"Key Insights\")\n",
        "    st.markdown(\"\"\"\n",
        "    - Males tend to report more competitive motivations (\"Compete/Win\")\n",
        "    - Female players emphasize \"Fun/Relax\" and \"Improve/Skill\" aspects\n",
        "    - \"Improve/Skill\" is common across all genders\n",
        "    - Significant association between gender and gaming motivation (p < 0.05)\n",
        "    \"\"\")\n",
        "\n",
        "    st.subheader(\"Interpretation:\")\n",
        "    st.markdown(\"\"\"\n",
        "    There is a statistically significant association between gender and gaming motivations. This means:\n",
        "    - Males and females have different motivational patterns when gaming.\n",
        "    - The observed differences (e.g., males emphasizing \"Compete/Win,\" females prioritizing \"Fun/Relax\") are unlikely due to random chance (p < 0.05).\n",
        "    \"\"\")\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# Save a copy of the original dataset for further visualization and correlation (before imputation)\n",
        "df_original = df.copy()\n",
        "\n",
        "\n",
        "\n",
        "# 1️⃣ **IMPUTE MISSING VALUES (Hours)**\n",
        "features_hours = [\"streams\", \"SPIN_T\", \"SPIN13\", \"SPIN16\", \"SPIN12\",\n",
        "                  \"Narcissism\", \"SPIN8\", \"SPIN10\", \"SPIN3\", \"SPIN14\"]\n",
        "df_filtered = df.dropna(subset=[\"Hours\"] + features_hours)\n",
        "X_train = df_filtered[features_hours]\n",
        "y_train = df_filtered[\"Hours\"]\n",
        "imputer = KNNImputer(n_neighbors=2)\n",
        "df[features_hours] = imputer.fit_transform(df[features_hours])\n",
        "df = df[~df[\"Hours\"].isin([420, 8000])]\n",
        "\n",
        "# 2️⃣ **IMPUTE MISSING VALUES (Narcissism)**\n",
        "features_narc = [\"GAD6\", \"GAD_T\", \"GAD5\"]\n",
        "df_filtered = df.dropna(subset=[\"Narcissism\"] + features_narc)\n",
        "X_train = df_filtered[features_narc]\n",
        "y_train = df_filtered[\"Narcissism\"]\n",
        "imputer = KNNImputer(n_neighbors=2)\n",
        "df[features_narc] = imputer.fit_transform(df[features_narc])\n",
        "\n",
        "# 3️⃣ **IMPUTE MISSING VALUES (Streams)**\n",
        "features_streams = [\"Hours\", \"SPIN_T\"]\n",
        "df_filtered = df.dropna(subset=[\"streams\"] + features_streams)\n",
        "X_train = df_filtered[features_streams]\n",
        "y_train = df_filtered[\"streams\"]\n",
        "imputer = KNNImputer(n_neighbors=2)\n",
        "df[features_streams] = imputer.fit_transform(df[features_streams])\n",
        "\n",
        "# 4️⃣ **REMOVE UNNECESSARY COLUMNS**\n",
        "s_drop = ['Unnamed: 0', 'Zeitstempel', 'Birthplace_ISO3', 'Residence_ISO3', 'highestleague',\n",
        "          'GAD1', 'GAD2', 'GAD3', 'GAD4', 'GAD5', 'GAD6', 'GAD7',\n",
        "          'SWL1', 'SWL2', 'SWL3', 'SWL4', 'SWL5',\n",
        "          'SPIN1', 'SPIN2', 'SPIN3', 'SPIN4', 'SPIN5', 'SPIN6', 'SPIN7', 'SPIN8',\n",
        "          'SPIN9', 'SPIN10', 'SPIN11', 'SPIN12', 'SPIN13', 'SPIN14', 'SPIN15',\n",
        "          'SPIN16', 'SPIN17', 'SPIN_T', 'accept']\n",
        "df = df.drop(columns=s_drop, errors='ignore')\n",
        "\n",
        "\n",
        "with tab2:\n",
        "\n",
        "    st.header(\"Gaming Hours vs Anxiety & Satisfaction with Life\")\n",
        "\n",
        "    # Improved filter presentation within Tab 2:\n",
        "    st.subheader(\"Filter Options\")\n",
        "    with st.container():\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1:\n",
        "            gender_filter = st.selectbox(\"Select Gender\", [\"All\"] + df[\"Gender\"].dropna().unique().tolist(), key=\"gender_filter_tab2\")\n",
        "            work_type = st.selectbox(\"Select Work Type\", [\"All\"] + df[\"Work\"].dropna().unique().tolist(), key=\"work_type_tab2\")\n",
        "        with col2:\n",
        "            degree = st.selectbox(\"Select Degree\", [\"All\"] + df[\"Degree\"].dropna().unique().tolist(), key=\"degree_tab2\")\n",
        "            residence = st.selectbox(\"Select Residence\", [\"All\"] + df[\"Residence\"].dropna().unique().tolist(), key=\"residence_tab2\")\n",
        "            game_type = st.selectbox(\"Select Game Type\", [\"All\"] + df[\"Game\"].dropna().unique().tolist(), key=\"game_type_tab2\")\n",
        "\n",
        "    # Apply filters based on the selections\n",
        "    filtered_df = df.copy()\n",
        "    if gender_filter != \"All\":\n",
        "        filtered_df = filtered_df[filtered_df[\"Gender\"] == gender_filter]\n",
        "    if work_type != \"All\":\n",
        "        filtered_df = filtered_df[filtered_df[\"Work\"] == work_type]\n",
        "    if degree != \"All\":\n",
        "        filtered_df = filtered_df[filtered_df[\"Degree\"] == degree]\n",
        "    if residence != \"All\":\n",
        "        filtered_df = filtered_df[filtered_df[\"Residence\"] == residence]\n",
        "    if game_type != \"All\":\n",
        "        filtered_df = filtered_df[filtered_df[\"Game\"] == game_type]\n",
        "\n",
        "    # Gaming Hours vs Anxiety (GAD_T)\n",
        "    if \"Hours\" in filtered_df.columns and \"GAD_T\" in filtered_df.columns:\n",
        "        fig1 = px.scatter(filtered_df, x=\"Hours\", y=\"GAD_T\", trendline=\"ols\",\n",
        "                          title=\"Gaming Hours vs Anxiety (GAD_T)\",\n",
        "                          color_discrete_sequence=['#FF6347'])\n",
        "        fig1.update_traces(line=dict(color='green'))\n",
        "        st.plotly_chart(fig1)\n",
        "\n",
        "    # Gaming Hours vs Satisfaction (SWL_T)\n",
        "    if \"Hours\" in filtered_df.columns and \"SWL_T\" in filtered_df.columns:\n",
        "        fig2 = px.scatter(filtered_df, x=\"Hours\", y=\"SWL_T\", trendline=\"ols\",\n",
        "                          title=\"Gaming Hours vs Satisfaction with Life\",\n",
        "                          color_discrete_sequence=['#1E90FF'])\n",
        "        fig2.update_traces(line=dict(color='red'))\n",
        "        st.plotly_chart(fig2)\n",
        "\n",
        "\n",
        "\n",
        "import plotly.express as px\n",
        "import scipy.stats as stats\n",
        "\n",
        "\n",
        "with tab3:\n",
        "\n",
        "    # Full Correlation Matrix (using non-imputed original data)\n",
        "    st.title(\"🔍 Full Correlation Matrix \")\n",
        "    numeric_df_original = df_original.drop(columns=s_drop, errors='ignore').select_dtypes(include=['number'])\n",
        "    correlation_matrix_original = numeric_df_original.corr()\n",
        "    st.subheader(\"📊 Correlation Table \")\n",
        "    st.dataframe(correlation_matrix_original.style.format(\"{:.4f}\").background_gradient(cmap='coolwarm'))\n",
        "\n",
        "    # Box plot comparing SWL_T across Work categories\n",
        "    fig = px.box(df, x='Work', y='SWL_T',\n",
        "                title=\"Life Satisfaction (SWL_T) by Employment Status\",\n",
        "                labels={\"Work\": \"Employment Status\", \"SWL_T\": \"Life Satisfaction (SWL_T)\"})\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "    # Prepare data for ANOVA: group SWL_T values by Work category\n",
        "    groups = [group['SWL_T'].dropna() for name, group in df.groupby('Work')]\n",
        "\n",
        "    # Perform one-way ANOVA\n",
        "    F, p = stats.f_oneway(*groups)\n",
        "\n",
        "    st.write(\"### ANOVA Results\")\n",
        "    st.write(f\"F-statistic = {F:.2f}, p-value = {p:.2f}\")\n",
        "\n",
        "    st.subheader(\"Interpretation:\")\n",
        "    st.markdown(\"\"\"\n",
        "    Life satisfaction (SWL_T) varies significantly across employment statuses:\n",
        "\n",
        "    - Large F-value (274.84) indicates strong group differences.\n",
        "\n",
        "    - Employed individuals (Mean SWL_T = 20.7) report higher life satisfaction than unemployed (14.7).\n",
        "\n",
        "    - Practical implication: Unemployment may exacerbate mental health challenges in gamers, while employment correlates with better well-being.\n",
        "    \"\"\")\n",
        "\n",
        "    # Calculate and display mean SWL_T per employment status\n",
        "    mean_values = df.groupby('Work')['SWL_T'].mean().round(1)\n",
        "    st.write(\"### Mean Life Satisfaction (SWL_T) by Employment Status\")\n",
        "    st.write(mean_values)\n",
        "\n",
        "    # Insight interpretation (example based on provided values)\n",
        "    st.markdown(\"\"\"\n",
        "    **Insight:** Employed individuals reported higher life satisfaction (Mean = 20.7) compared to unemployed individuals (Mean = 14.7).\n",
        "    The ANOVA indicates that these differences are statistically significant (F = 274.84, p = 0.00).\n",
        "    \"\"\")\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Gamers Clustering Based on Habits and Mental Health\n",
        "\n",
        "with tab4:\n",
        "    st.title(\"🔍 Gamers Clustering Based on Habits and Mental Health\")\n",
        "\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.cluster import KMeans\n",
        "    from sklearn.decomposition import PCA\n",
        "\n",
        "    cluster_vars = ['Hours', 'GAD_T', 'SWL_T']\n",
        "\n",
        "    clustering_data = df[cluster_vars].dropna()\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    scaled_data = scaler.fit_transform(clustering_data)\n",
        "\n",
        "    kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "    clusters = kmeans.fit_predict(scaled_data)\n",
        "    clustering_data['Cluster'] = clusters\n",
        "\n",
        "    pca = PCA(n_components=2, random_state=42)\n",
        "    pca_components = pca.fit_transform(scaled_data)\n",
        "    clustering_data['PC1'] = pca_components[:, 0]\n",
        "    clustering_data['PC2'] = pca_components[:, 1]\n",
        "\n",
        "    fig_cluster = px.scatter(clustering_data, x='PC1', y='PC2', color='Cluster',\n",
        "                            title=\"Gamers Clusters (PCA-Reduced)\",\n",
        "                            labels={\"PC1\": \"Principal Component 1\", \"PC2\": \"Principal Component 2\"},\n",
        "                            color_discrete_sequence=px.colors.qualitative.Bold)\n",
        "    st.plotly_chart(fig_cluster)\n",
        "\n",
        "    cluster_profiles = clustering_data.groupby('Cluster')[cluster_vars].mean().round(1)\n",
        "    st.write(\"### Cluster Profiles\")\n",
        "    st.dataframe(cluster_profiles)\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    Real-World Analogy:\n",
        "    - Cluster 0 (Balanced Players)\n",
        "\n",
        "      Gaming Hours: Moderate (18.9 hours)\n",
        "\n",
        "      Anxiety (GAD_T): Low (2.8)\n",
        "\n",
        "      Life Satisfaction (SWL_T): High (23.7)\n",
        "\n",
        "      Profile: Players with healthy gaming habits who maintain good mental health and life satisfaction. Likely play for enjoyment/skill development without excessive time commitment.\n",
        "\n",
        "    - Cluster 1 (At-Risk Players)\n",
        "\n",
        "      Gaming Hours: High (26 hours)\n",
        "\n",
        "      Anxiety (GAD_T): Elevated (9.1)\n",
        "\n",
        "      Life Satisfaction (SWL_T): Low (13.4)\n",
        "\n",
        "      Profile: Players showing potential signs of problematic gaming behavior - longer playtimes correlate with higher anxiety and reduced life satisfaction. May be using gaming as an escape mechanism.\n",
        "    \"\"\")\n",
        "\n",
        "    st.subheader(\" Key Psychological Insight:\")\n",
        "    st.markdown(\"\"\"\n",
        "\n",
        "    The pattern shows an inverse relationship between gaming hours and mental health metrics:\n",
        "\n",
        "    ↑ More gaming hours = ↑ Anxiety + ↓ Life satisfaction\n",
        "\n",
        "    ↓ Moderate gaming = ↓ Anxiety + ↑ Life satisfaction\n",
        "\n",
        "    This aligns with clinical observations that excessive gaming can be both a symptom and contributor to mental health challenges.\n",
        "\n",
        "    \"\"\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au5BV7HtXk6Y",
        "outputId": "23f3bfd1-2f78-4974-a17e-67a41d47014a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "LHL_qtqvmyml"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.set_auth_token(\"2Z2OwWheOVA9BCe2FBstfdc9NTt_3FnAyeXY2cqFZ3x54WeAv\")"
      ],
      "metadata": {
        "id": "0oe5Kdwymyml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "572df6d2-0545-4854-e19b-43c430da91a1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup streamlit run app.py &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6905899a-530f-4f57-bbd9-bad24bf4ece4",
        "id": "pI8BTE18myml"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "public_url = ngrok.connect(8501)\n",
        "print(public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af243761-5be9-4414-e4c2-baabd7466690",
        "id": "PLz8h4A2myml"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NgrokTunnel: \"https://6035-34-48-96-142.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jtlLqek9XGPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#games_sales"
      ],
      "metadata": {
        "id": "g1FGgZARAfK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "st.set_page_config(page_title=\"Game Sales Dashboard\", page_icon=\"🎮\", layout=\"wide\")\n",
        "\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "@keyframes fadeIn {\n",
        "  from {opacity: 0;}\n",
        "  to {opacity: 1;}\n",
        "}\n",
        ".fade-in {\n",
        "  animation: fadeIn 1s ease-in;\n",
        "}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    df = pd.read_csv(\"Video_Games_Sales_as_at_22_Dec_2016.csv\")\n",
        "    df[\"User_Score\"] = pd.to_numeric(df[\"User_Score\"], errors='coerce')\n",
        "    median_year = int(df[\"Year_of_Release\"].median())\n",
        "    df[\"Year_of_Release\"].fillna(median_year, inplace=True)\n",
        "\n",
        "\n",
        "    numeric_columns = [\"Critic_Score\", \"Critic_Count\", \"User_Score\", \"User_Count\"]\n",
        "    imputer = KNNImputer(n_neighbors=5)\n",
        "    df[numeric_columns] = imputer.fit_transform(df[numeric_columns])\n",
        "\n",
        "    return df\n",
        "\n",
        "df = load_data()\n",
        "\n",
        "st.sidebar.header(\"🔍 Filters\")\n",
        "selected_year_range = st.sidebar.slider(\n",
        "    \"Select Year Range\",\n",
        "    min_value=int(df['Year_of_Release'].min()),\n",
        "    max_value=int(df['Year_of_Release'].max()),\n",
        "    value=(2000, 2016)\n",
        ")\n",
        "\n",
        "selected_genres = st.sidebar.multiselect(\n",
        "    \"Select Genres\",\n",
        "    options=df['Genre'].unique(),\n",
        "    default=['Action', 'Sports', 'Shooter']\n",
        ")\n",
        "\n",
        "\n",
        "st.title(\"🎮 Video Game Sales Dashboard\")\n",
        "st.markdown('<div class=\"fade-in\">', unsafe_allow_html=True)\n",
        "\n",
        "filtered_df = df[\n",
        "    (df['Year_of_Release'].between(*selected_year_range)) &\n",
        "    (df['Genre'].isin(selected_genres))\n",
        "]\n",
        "\n",
        "\n",
        "col1, col2, col3 = st.columns(3)\n",
        "with col1:\n",
        "    st.metric(\"Total Games Analyzed\", len(filtered_df))\n",
        "with col2:\n",
        "    st.metric(\"Total Global Sales\", f\"${filtered_df['Global_Sales'].sum():,.1f}B\")\n",
        "with col3:\n",
        "    st.metric(\"Average Critic Score\", f\"{filtered_df['Critic_Score'].mean():.1f}/100\")\n",
        "\n",
        "\n",
        "tab1, tab2, tab3, tab4, tab5 = st.tabs([\n",
        "    \"📊 Sales Analysis\",\n",
        "    \"🌟 Score Correlations\",\n",
        "    \"🌍 Regional Insights\",\n",
        "    \"🎮 Game Clusters\",\n",
        "    \"📝 References\"\n",
        "])\n",
        "\n",
        "with tab1:\n",
        "    st.header(\"Sales Performance Analysis\")\n",
        "\n",
        "\n",
        "    num_games = st.slider(\"Select Number of Top Games\", 5, 20, 10)\n",
        "    top_games = filtered_df.nlargest(num_games, 'Global_Sales')\n",
        "\n",
        "    fig = px.bar(top_games,\n",
        "                 x='Global_Sales',\n",
        "                 y='Name',\n",
        "                 orientation='h',\n",
        "                 color='Platform',\n",
        "                 title=f\"Top {num_games} Best-Selling Games\",\n",
        "                 labels={'Global_Sales': 'Global Sales (Millions)'})\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "\n",
        "    st.subheader(\"Sales Trends Over Time\")\n",
        "    trend_data = filtered_df.groupby(\"Year_of_Release\")[\"Global_Sales\"].sum().reset_index()\n",
        "    fig = px.area(trend_data,\n",
        "                  x='Year_of_Release',\n",
        "                  y='Global_Sales',\n",
        "                  markers=True,\n",
        "                  title=\"Global Sales Trend Over Time\")\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "with tab2:\n",
        "    st.header(\"Review Score Analysis\")\n",
        "\n",
        "\n",
        "    score_type = st.radio(\"Select Score Type\", ['Critic_Score', 'User_Score'])\n",
        "\n",
        "    fig = px.scatter(filtered_df,\n",
        "                     x=score_type,\n",
        "                     y='Global_Sales',\n",
        "                     color='Genre',\n",
        "                     size='Critic_Count',\n",
        "                     hover_name='Name',\n",
        "                     title=f\"{score_type.replace('_', ' ')} vs Global Sales\")\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "    st.subheader(\"Regional Sales Correlations\")\n",
        "    corr_matrix = filtered_df[['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales']].corr()\n",
        "    fig = px.imshow(corr_matrix,\n",
        "                    text_auto=True,\n",
        "                    color_continuous_scale='Blues',\n",
        "                    title=\"Regional Sales Correlation Heatmap\")\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "with tab3:\n",
        "    st.header(\"Regional Market Analysis\")\n",
        "\n",
        "\n",
        "    region = st.selectbox(\"Select Region\", ['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales'])\n",
        "    regional_data = filtered_df.groupby('Genre')[region].sum().reset_index()\n",
        "\n",
        "    fig = px.pie(regional_data,\n",
        "                 names='Genre',\n",
        "                 values=region,\n",
        "                 title=f\"{region.replace('_', ' ')} Distribution by Genre\")\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "\n",
        "    st.subheader(\"Top Publishers by Region\")\n",
        "    publishers = filtered_df.groupby('Publisher')[['NA_Sales', 'EU_Sales', 'JP_Sales']].sum()\n",
        "    fig = px.bar(publishers.nlargest(5, 'NA_Sales'),\n",
        "                 orientation='h',\n",
        "                 title=\"Top Publishers in North America\")\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "with tab4:\n",
        "    st.header(\"Game Clustering Analysis\")\n",
        "\n",
        "\n",
        "    n_clusters = st.slider(\"Select Number of Clusters\", 2, 5, 3)\n",
        "\n",
        "    cluster_df = filtered_df[['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales']].dropna()\n",
        "    scaler = StandardScaler()\n",
        "    scaled_data = scaler.fit_transform(cluster_df)\n",
        "\n",
        "\n",
        "    kmeans = KMeans(n_clusters=n_clusters, n_init=10)\n",
        "    cluster_df['Cluster'] = kmeans.fit_predict(scaled_data)\n",
        "\n",
        "\n",
        "    pca = PCA(n_components=2)\n",
        "    pca_results = pca.fit_transform(scaled_data)\n",
        "    cluster_df['PC1'] = pca_results[:, 0]\n",
        "    cluster_df['PC2'] = pca_results[:, 1]\n",
        "\n",
        "    fig = px.scatter(cluster_df,\n",
        "                     x='PC1',\n",
        "                     y='PC2',\n",
        "                     color='Cluster',\n",
        "                     hover_data=['NA_Sales', 'EU_Sales'],\n",
        "                     title=\"PCA Visualization of Game Clusters\")\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "    st.subheader(\"Cluster Characteristics\")\n",
        "    profile = cluster_df.groupby('Cluster').mean()\n",
        "    st.dataframe(profile.style.background_gradient(cmap='Blues'), use_container_width=True)\n",
        "\n",
        "st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "with tab5:\n",
        "\n",
        "    st.header(\"\"\"Thank you\"\"\")\n",
        "    st.header(\"References\")\n",
        "    st.markdown(\"\"\"\n",
        "    - The Gaming sales dataset from [Kaggle Dataset](https://www.kaggle.com/datasets/gregorut/videogamesales)\n",
        "\n",
        "    - The Gaming Psychological dataset from Open Science Framework (https://osf.io/vnbxk/)\n",
        "\n",
        "    \"\"\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Tz8_mKpAAgPY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a5efd06-cc0a-407c-fc39-026de2a9bfbb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#605"
      ],
      "metadata": {
        "id": "ERwvT7rKhKfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "import plotly.express as px\n",
        "from sklearn.impute import KNNImputer\n",
        "import nltk\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from scipy.stats import chi2_contingency, f_oneway\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Initialize session state for page navigation\n",
        "if \"page\" not in st.session_state:\n",
        "    st.session_state.page = \"Home\"\n",
        "\n",
        "# Sidebar with an icon button to switch pages\n",
        "if st.sidebar.button(\"🔄 NL <-> OJ\"):\n",
        "    st.session_state.page = \"Dashboard\" if st.session_state.page == \"Home\" else \"Home\"\n",
        "\n",
        "\n",
        "if st.session_state.page == \"Home\":\n",
        "\n",
        "# Cache data loading for better performance\n",
        "    @st.cache_data\n",
        "    def load_data():\n",
        "        return pd.read_csv(\"/content/GamingStudy_data.csv\", encoding='latin-1')\n",
        "\n",
        "    nltk.download('wordnet')\n",
        "    nltk.download('omw-1.4')\n",
        "\n",
        "    # Enhanced categorization with priority system\n",
        "    categories = {\n",
        "        'Distraction': ['distract', 'escape', 'forget', 'stress', 'anxiety', 'avoid',\n",
        "                        'reality', 'pain', 'trouble', 'problem', 'depression', 'nervous'],\n",
        "        'Habit/Time Pass': ['habit', 'time', 'pass', 'bored', 'routine', 'kill time',\n",
        "                            'occupied', 'waste', 'fill', 'nothing', 'procrastinate'],\n",
        "        'Social': ['friend', 'team', 'coop', 'multiplayer', 'social', 'together',\n",
        "                  'community', 'connect', 'bond', 'relationship', 'with others', 'family'],\n",
        "        'Compete/Win': ['win', 'compete', 'victory', 'rank', 'ladder', 'gm', 'climb',\n",
        "                        'top', 'leaderboard', 'dominate', 'triumph', 'beat', 'champion'],\n",
        "        'Improve/Skill': ['improve', 'learn', 'skill', 'progress', 'master', 'practice',\n",
        "                          'better', 'develop', 'growth', 'hone', 'enhance', 'advance'],\n",
        "        'Fun/Relax': ['fun', 'relax', 'enjoy', 'chill', 'unwind', 'distress', 'joy',\n",
        "                      'pleasure', 'entertain', 'distraction', 'happiness']\n",
        "    }\n",
        "    category_priority = ['Distraction', 'Habit/Time Pass', 'Social',\n",
        "                        'Compete/Win', 'Improve/Skill', 'Fun/Relax']\n",
        "\n",
        "    def categorize_whyplay(text):\n",
        "        text = re.sub(r'[^\\w\\s]', '', str(text).lower())\n",
        "        tokens = text.split()\n",
        "        verb_tokens = [WordNetLemmatizer().lemmatize(word, pos='v') for word in tokens]\n",
        "        combined_tokens = set(tokens) | set(verb_tokens)\n",
        "\n",
        "        matched = []\n",
        "        for category in category_priority:\n",
        "            keywords = categories[category]\n",
        "            for keyword in keywords:\n",
        "                if any(keyword in token for token in combined_tokens):\n",
        "                    matched.append(category)\n",
        "                    break  # Move to next category after first match\n",
        "\n",
        "        if 'all' in combined_tokens or 'every' in combined_tokens:\n",
        "            return category_priority\n",
        "        return matched if matched else ['Other']\n",
        "\n",
        "    # Load and process data\n",
        "    df = load_data()\n",
        "    df['whyplay_cats'] = df['whyplay'].apply(categorize_whyplay)\n",
        "    df_exploded = df.explode('whyplay_cats')\n",
        "\n",
        "    st.title(\"Data Story on Gaming 🎮\")\n",
        "    # Streamlit app\n",
        "\n",
        "    tab0, tab1, tab2, tab3, tab4 = st.tabs([\n",
        "        \"📝 Introduction\",\n",
        "        \"🌟 Reason vs Gender\",\n",
        "        \"🌍 Addiction and Satisfaction\",\n",
        "        \"📊 Math behind Games\",\n",
        "        \"🎮 Game Clusters\"\n",
        "    ])\n",
        "\n",
        "    with tab0:\n",
        "        st.subheader(\"A DATA 605 Project by Lalith and Ojas\")\n",
        "        st.subheader(\"Why Gaming ??!!\")\n",
        "        st.markdown(\"\"\"\n",
        "        Did you know that the biggest industry in terms of revenue isn’t movies or music? Surprisingly,\n",
        "        it’s the video gaming industry, which generated a staggering 💲187 billion in 2023. In comparison,\n",
        "        the movie industry brought in 💲133 billion, while the music industry trailed far behind at 💲28 billion.\n",
        "        That means video games earn more than both industries combined.With such immense growth and potential,\n",
        "        it's clear that the video game industry is a gold mine worth exploring.\n",
        "        \"\"\")\n",
        "\n",
        "        st.markdown(\"\"\"\n",
        "\n",
        "        1. Gaming Industry\n",
        "    -\t2022: $184 billion (Newzoo)\n",
        "    Driven by mobile, console, and PC gaming, with strong growth in emerging markets.\n",
        "    -\t2023: $187 billion (estimated)\n",
        "      Moderate growth due to post-pandemic normalization and mobile dominance.\n",
        "    -\t2024: $200 billion (projected)\n",
        "      Expected growth from cloud gaming, esports, and next-gen hardware.\n",
        "    ________________________________________\n",
        "    2. Music Industry\n",
        "    -\t2022: $26.2 billion (IFPI)\n",
        "      Streaming accounted for 67% of recorded music revenue.\n",
        "    -\t2023: $28–29 billion (estimated)\n",
        "      Continued growth in streaming and live events post-pandemic.\n",
        "    -\t2024: $31–33 billion (projected)\n",
        "      Expansion in emerging markets and vinyl/cassette nostalgia trends.\n",
        "    ________________________________________\n",
        "    3. Movie Industry\n",
        "    -\t2022:\tTheatrical: \\$26 billion (Global Box Office)\n",
        "      Total (including streaming): $90 billion (MPA estimates).\n",
        "    -\t2023:\tTheatrical: \\$33 billion (Box Office Mojo)\n",
        "      Total: $100 billion (streaming platforms like Netflix and Disney+).\n",
        "    -\t2024: $105–110 billion (projected)\n",
        "      Hybrid releases (theatrical + streaming) and international markets driving growth.\n",
        "    ________________________________________\n",
        "    4. Sports Industry\n",
        "    -\t2022: $487 billion (Statista)\n",
        "      Includes media rights, sponsorships, merchandise, and live events.\n",
        "    -\t2023: $500–520 billion (estimated)\n",
        "      Recovery in live attendance and rising media deals (e.g., NFL, Premier League).\n",
        "    -\t2024: $550–600 billion (projected)\n",
        "      Growth in digital streaming rights and global events (e.g., Olympics, FIFA World Cup)\n",
        "\n",
        "        \"\"\")\n",
        "\n",
        "        st.subheader(\"Info about dataset\")\n",
        "\n",
        "        st.markdown(\"\"\"\n",
        "        GAD     [0 --> 3]   [not at all,  several days,  over half the days, nearly always]\n",
        "\n",
        "    - If u feel nervous, anxious\n",
        "    - not being able to control or stop worrying\n",
        "    - worrying too much about other things\n",
        "    - trouble relaxing\n",
        "    - being restless\n",
        "    - becoming easily annoyd or irritated\n",
        "    - feeling awfull as somthin bad is goin to happen\n",
        "    \"\"\")\n",
        "\n",
        "        st.markdown(\"<span style='color: red; font-weight: bold;'>More is Bad!</span>\", unsafe_allow_html=True)\n",
        "\n",
        "        st.markdown(\"\"\"\n",
        "\n",
        "    SWL    [1 --> 7] [Strongly disagree, Disagree, silghtly disagree, neutral, silghtly agre, agree, strongly disagree]\n",
        "\n",
        "    - satisfied\n",
        "    - ideal\n",
        "    - excellent life\n",
        "    - wont not change my life\n",
        "    - gotten important things in I want in my life\n",
        "    \"\"\")\n",
        "\n",
        "        st.markdown(\"<span style='color: green; font-weight: bold;'>More is Good!</span>\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "    with tab1:\n",
        "        st.header(\"Behavioral Analysis\")\n",
        "\n",
        "        # Create filter buttons in columns\n",
        "\n",
        "        filter_col1, filter_col2, filter_col3 = st.columns(3)\n",
        "\n",
        "        # Gender Filter\n",
        "        with filter_col1:\n",
        "            gender_options = [\"All\"] + df['Gender'].dropna().unique().tolist()\n",
        "            selected_gender = st.radio(\n",
        "                \"Gender\",\n",
        "                gender_options,\n",
        "                index=0,\n",
        "                key=\"gender_filter\"\n",
        "            )\n",
        "\n",
        "        # Apply filters\n",
        "        filtered_exploded = df_exploded.copy()\n",
        "\n",
        "        if selected_gender != \"All\":\n",
        "            filtered_exploded = filtered_exploded[filtered_exploded['Gender'] == selected_gender]\n",
        "\n",
        "        # Create visualization with filtered data\n",
        "        fig = px.bar(filtered_exploded['whyplay_cats'].value_counts().reset_index(),\n",
        "                    x='count', y='whyplay_cats', orientation='h',\n",
        "                    title=f\"Gaming Motivations Breakdown\",\n",
        "                    labels={'whyplay_cats': 'Motivation Category', 'count': 'Player Count'},\n",
        "                    color='whyplay_cats',\n",
        "                    color_discrete_sequence=px.colors.qualitative.Pastel)\n",
        "\n",
        "        # Dynamic subtitle with active filters\n",
        "        filter_text = []\n",
        "        if selected_gender != \"All\": filter_text.append(f\"Gender: {selected_gender}\")\n",
        "\n",
        "\n",
        "        if filter_text:\n",
        "            st.caption(f\"Active filters: {', '.join(filter_text)}\")\n",
        "\n",
        "        fig.update_layout(\n",
        "            height=500,\n",
        "            width=800,\n",
        "            yaxis_title=\"Motivation Category\",\n",
        "            xaxis_title=\"Number of Players\",\n",
        "            legend_title=\"Motivation\",\n",
        "            showlegend=False  # Cleaner look for horizontal bars\n",
        "        )\n",
        "\n",
        "        st.plotly_chart(fig)\n",
        "        # Chi-square test for association between Gender and whyplay_cats\n",
        "        st.header(\"Statistical Analysis\")\n",
        "        contingency_table = pd.crosstab(df_exploded['Gender'], df_exploded['whyplay_cats'])\n",
        "        chi2, p, _, _ = chi2_contingency(contingency_table)\n",
        "\n",
        "        st.subheader(\"Chi-Square Test Results\")\n",
        "        st.markdown(f\"\"\"\n",
        "        - **Chi-Square Statistic**: `{chi2:.2f}`\n",
        "        - **P-value**: `{p:.5f}`\n",
        "        - **Significance**: {'✅ Significant' if p < 0.05 else '❌ Not Significant'}\n",
        "        \"\"\")\n",
        "        st.subheader(\"Key Insights\")\n",
        "        st.markdown(\"\"\"\n",
        "        - Males tend to report more competitive motivations (\"Compete/Win\")\n",
        "        - Female players emphasize \"Fun/Relax\" and \"Improve/Skill\" aspects\n",
        "        - \"Improve/Skill\" is common across all genders\n",
        "        - Significant association between gender and gaming motivation (p < 0.05)\n",
        "        \"\"\")\n",
        "\n",
        "        st.subheader(\"Interpretation:\")\n",
        "        st.markdown(\"\"\"\n",
        "        There is a statistically significant association between gender and gaming motivations. This means:\n",
        "        - Males and females have different motivational patterns when gaming.\n",
        "        - The observed differences (e.g., males emphasizing \"Compete/Win,\" females prioritizing \"Fun/Relax\") are unlikely due to random chance (p < 0.05).\n",
        "        \"\"\")\n",
        "\n",
        "\n",
        "    # ------------------------------------------------------------------------------\n",
        "\n",
        "    # Save a copy of the original dataset for further visualization and correlation (before imputation)\n",
        "    df_original = df.copy()\n",
        "\n",
        "\n",
        "\n",
        "    # 1️⃣ **IMPUTE MISSING VALUES (Hours)**\n",
        "    features_hours = [\"streams\", \"SPIN_T\", \"SPIN13\", \"SPIN16\", \"SPIN12\",\n",
        "                      \"Narcissism\", \"SPIN8\", \"SPIN10\", \"SPIN3\", \"SPIN14\"]\n",
        "    df_filtered = df.dropna(subset=[\"Hours\"] + features_hours)\n",
        "    X_train = df_filtered[features_hours]\n",
        "    y_train = df_filtered[\"Hours\"]\n",
        "    imputer = KNNImputer(n_neighbors=2)\n",
        "    df[features_hours] = imputer.fit_transform(df[features_hours])\n",
        "    df = df[~df[\"Hours\"].isin([420, 8000])]\n",
        "\n",
        "    # 2️⃣ **IMPUTE MISSING VALUES (Narcissism)**\n",
        "    features_narc = [\"GAD6\", \"GAD_T\", \"GAD5\"]\n",
        "    df_filtered = df.dropna(subset=[\"Narcissism\"] + features_narc)\n",
        "    X_train = df_filtered[features_narc]\n",
        "    y_train = df_filtered[\"Narcissism\"]\n",
        "    imputer = KNNImputer(n_neighbors=2)\n",
        "    df[features_narc] = imputer.fit_transform(df[features_narc])\n",
        "\n",
        "    # 3️⃣ **IMPUTE MISSING VALUES (Streams)**\n",
        "    features_streams = [\"Hours\", \"SPIN_T\"]\n",
        "    df_filtered = df.dropna(subset=[\"streams\"] + features_streams)\n",
        "    X_train = df_filtered[features_streams]\n",
        "    y_train = df_filtered[\"streams\"]\n",
        "    imputer = KNNImputer(n_neighbors=2)\n",
        "    df[features_streams] = imputer.fit_transform(df[features_streams])\n",
        "\n",
        "    # 4️⃣ **REMOVE UNNECESSARY COLUMNS**\n",
        "    s_drop = ['Unnamed: 0', 'Zeitstempel', 'Birthplace_ISO3', 'Residence_ISO3', 'highestleague',\n",
        "              'GAD1', 'GAD2', 'GAD3', 'GAD4', 'GAD5', 'GAD6', 'GAD7',\n",
        "              'SWL1', 'SWL2', 'SWL3', 'SWL4', 'SWL5',\n",
        "              'SPIN1', 'SPIN2', 'SPIN3', 'SPIN4', 'SPIN5', 'SPIN6', 'SPIN7', 'SPIN8',\n",
        "              'SPIN9', 'SPIN10', 'SPIN11', 'SPIN12', 'SPIN13', 'SPIN14', 'SPIN15',\n",
        "              'SPIN16', 'SPIN17', 'SPIN_T', 'accept']\n",
        "    df = df.drop(columns=s_drop, errors='ignore')\n",
        "\n",
        "\n",
        "    with tab2:\n",
        "\n",
        "        st.header(\"Gaming Hours vs Anxiety & Satisfaction with Life\")\n",
        "\n",
        "        with st.container():\n",
        "            col1, col2 = st.columns(2)\n",
        "            with col1:\n",
        "                gender_filter = st.selectbox(\"Select Gender\", [\"All\"] + df[\"Gender\"].dropna().unique().tolist(), key=\"gender_filter_tab2\")\n",
        "                work_type = st.selectbox(\"Select Work Type\", [\"All\"] + df[\"Work\"].dropna().unique().tolist(), key=\"work_type_tab2\")\n",
        "            with col2:\n",
        "                degree = st.selectbox(\"Select Degree\", [\"All\"] + df[\"Degree\"].dropna().unique().tolist(), key=\"degree_tab2\")\n",
        "                residence = st.selectbox(\"Select Residence\", [\"All\"] + df[\"Residence\"].dropna().unique().tolist(), key=\"residence_tab2\")\n",
        "                game_type = st.selectbox(\"Select Game Type\", [\"All\"] + df[\"Game\"].dropna().unique().tolist(), key=\"game_type_tab2\")\n",
        "\n",
        "        # Apply filters based on the selections\n",
        "        filtered_df = df.copy()\n",
        "        if gender_filter != \"All\":\n",
        "            filtered_df = filtered_df[filtered_df[\"Gender\"] == gender_filter]\n",
        "        if work_type != \"All\":\n",
        "            filtered_df = filtered_df[filtered_df[\"Work\"] == work_type]\n",
        "        if degree != \"All\":\n",
        "            filtered_df = filtered_df[filtered_df[\"Degree\"] == degree]\n",
        "        if residence != \"All\":\n",
        "            filtered_df = filtered_df[filtered_df[\"Residence\"] == residence]\n",
        "        if game_type != \"All\":\n",
        "            filtered_df = filtered_df[filtered_df[\"Game\"] == game_type]\n",
        "\n",
        "        # Gaming Hours vs Anxiety (GAD_T)\n",
        "        if \"Hours\" in filtered_df.columns and \"GAD_T\" in filtered_df.columns:\n",
        "            fig1 = px.scatter(filtered_df, x=\"Hours\", y=\"GAD_T\", trendline=\"ols\",\n",
        "                              title=\"Gaming Hours vs Anxiety (GAD_T)\",\n",
        "                              color_discrete_sequence=['#FF6347'])\n",
        "            fig1.update_traces(line=dict(color='green'))\n",
        "            st.plotly_chart(fig1)\n",
        "\n",
        "        # Gaming Hours vs Satisfaction (SWL_T)\n",
        "        if \"Hours\" in filtered_df.columns and \"SWL_T\" in filtered_df.columns:\n",
        "            fig2 = px.scatter(filtered_df, x=\"Hours\", y=\"SWL_T\", trendline=\"ols\",\n",
        "                              title=\"Gaming Hours vs Satisfaction with Life\",\n",
        "                              color_discrete_sequence=['#1E90FF'])\n",
        "            fig2.update_traces(line=dict(color='red'))\n",
        "            st.plotly_chart(fig2)\n",
        "\n",
        "\n",
        "\n",
        "    import plotly.express as px\n",
        "    import scipy.stats as stats\n",
        "\n",
        "\n",
        "    with tab3:\n",
        "\n",
        "        # Full Correlation Matrix (using non-imputed original data)\n",
        "\n",
        "        numeric_df_original = df_original.drop(columns=s_drop, errors='ignore').select_dtypes(include=['number'])\n",
        "        correlation_matrix_original = numeric_df_original.corr()\n",
        "        st.subheader(\"📊 Correlation Table \")\n",
        "        st.dataframe(correlation_matrix_original.style.format(\"{:.4f}\").background_gradient(cmap='coolwarm'))\n",
        "\n",
        "        # Box plot comparing SWL_T across Work categories\n",
        "        fig = px.box(df, x='Work', y='SWL_T',\n",
        "                    title=\"Life Satisfaction (SWL_T) by Employment Status\",\n",
        "                    labels={\"Work\": \"Employment Status\", \"SWL_T\": \"Life Satisfaction (SWL_T)\"})\n",
        "        st.plotly_chart(fig)\n",
        "\n",
        "        # Prepare data for ANOVA: group SWL_T values by Work category\n",
        "        groups = [group['SWL_T'].dropna() for name, group in df.groupby('Work')]\n",
        "\n",
        "        # Perform one-way ANOVA\n",
        "        F, p = stats.f_oneway(*groups)\n",
        "\n",
        "        st.write(\"### ANOVA Results\")\n",
        "        st.write(f\"F-statistic = {F:.2f}, p-value = {p:.2f}\")\n",
        "\n",
        "        st.subheader(\"Interpretation:\")\n",
        "        st.markdown(\"\"\"\n",
        "        Life satisfaction (SWL_T) varies significantly across employment statuses:\n",
        "\n",
        "        - Large F-value (274.84) indicates strong group differences.\n",
        "\n",
        "        - Employed individuals (Mean SWL_T = 20.7) report higher life satisfaction than unemployed (14.7).\n",
        "\n",
        "        - Practical implication: Unemployment may exacerbate mental health challenges in gamers, while employment correlates with better well-being.\n",
        "        \"\"\")\n",
        "\n",
        "        # Calculate and display mean SWL_T per employment status\n",
        "        mean_values = df.groupby('Work')['SWL_T'].mean().round(1)\n",
        "        st.write(\"### Mean Life Satisfaction (SWL_T) by Employment Status\")\n",
        "        st.write(mean_values)\n",
        "\n",
        "        # Insight interpretation (example based on provided values)\n",
        "        st.markdown(\"\"\"\n",
        "        **Insight:** Employed individuals reported higher life satisfaction (Mean = 20.7) compared to unemployed individuals (Mean = 14.7).\n",
        "        The ANOVA indicates that these differences are statistically significant (F = 274.84, p = 0.00).\n",
        "        \"\"\")\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # Gamers Clustering Based on Habits and Mental Health\n",
        "\n",
        "    with tab4:\n",
        "        st.title(\"🔍 Gamers Clustering Based on Habits and Mental Health\")\n",
        "\n",
        "        from sklearn.preprocessing import StandardScaler\n",
        "        from sklearn.cluster import KMeans\n",
        "        from sklearn.decomposition import PCA\n",
        "\n",
        "        cluster_vars = ['Hours', 'GAD_T', 'SWL_T']\n",
        "\n",
        "        clustering_data = df[cluster_vars].dropna()\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        scaled_data = scaler.fit_transform(clustering_data)\n",
        "\n",
        "        kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "        clusters = kmeans.fit_predict(scaled_data)\n",
        "        clustering_data['Cluster'] = clusters\n",
        "\n",
        "        pca = PCA(n_components=2, random_state=42)\n",
        "        pca_components = pca.fit_transform(scaled_data)\n",
        "        clustering_data['PC1'] = pca_components[:, 0]\n",
        "        clustering_data['PC2'] = pca_components[:, 1]\n",
        "\n",
        "        fig_cluster = px.scatter(clustering_data, x='PC1', y='PC2', color='Cluster',\n",
        "                                title=\"Gamers Clusters (PCA-Reduced)\",\n",
        "                                labels={\"PC1\": \"Principal Component 1\", \"PC2\": \"Principal Component 2\"},\n",
        "                                color_discrete_sequence=px.colors.qualitative.Bold)\n",
        "        st.plotly_chart(fig_cluster)\n",
        "\n",
        "        cluster_profiles = clustering_data.groupby('Cluster')[cluster_vars].mean().round(1)\n",
        "        st.write(\"### Cluster Profiles\")\n",
        "        st.dataframe(cluster_profiles)\n",
        "\n",
        "        st.markdown(\"\"\"\n",
        "        Real-World Analogy:\n",
        "        - Cluster 0 (Balanced Players)\n",
        "\n",
        "          Gaming Hours: Moderate (18.9 hours)\n",
        "\n",
        "          Anxiety (GAD_T): Low (2.8)\n",
        "\n",
        "          Life Satisfaction (SWL_T): High (23.7)\n",
        "\n",
        "          Profile: Players with healthy gaming habits who maintain good mental health and life satisfaction. Likely play for enjoyment/skill development without excessive time commitment.\n",
        "\n",
        "        - Cluster 1 (At-Risk Players)\n",
        "\n",
        "          Gaming Hours: High (26 hours)\n",
        "\n",
        "          Anxiety (GAD_T): Elevated (9.1)\n",
        "\n",
        "          Life Satisfaction (SWL_T): Low (13.4)\n",
        "\n",
        "          Profile: Players showing potential signs of problematic gaming behavior - longer playtimes correlate with higher anxiety and reduced life satisfaction. May be using gaming as an escape mechanism.\n",
        "        \"\"\")\n",
        "\n",
        "        st.subheader(\" Key Psychological Insight:\")\n",
        "        st.markdown(\"\"\"\n",
        "\n",
        "        The pattern shows an inverse relationship between gaming hours and mental health metrics:\n",
        "\n",
        "        ↑ More gaming hours = ↑ Anxiety + ↓ Life satisfaction\n",
        "\n",
        "        ↓ Moderate gaming = ↓ Anxiety + ↑ Life satisfaction\n",
        "\n",
        "        This aligns with clinical observations that excessive gaming can be both a symptom and contributor to mental health challenges.\n",
        "\n",
        "        \"\"\")\n",
        "\n",
        "        #----------------------oj---------------------\n",
        "else:\n",
        "\n",
        "\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    <style>\n",
        "    @keyframes fadeIn {\n",
        "      from {opacity: 0;}\n",
        "      to {opacity: 1;}\n",
        "    }\n",
        "    .fade-in {\n",
        "      animation: fadeIn 1s ease-in;\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    @st.cache_data\n",
        "    def load_data():\n",
        "        df = pd.read_csv(\"Video_Games_Sales_as_at_22_Dec_2016.csv\")\n",
        "        df[\"User_Score\"] = pd.to_numeric(df[\"User_Score\"], errors='coerce')\n",
        "        median_year = int(df[\"Year_of_Release\"].median())\n",
        "        df[\"Year_of_Release\"].fillna(median_year, inplace=True)\n",
        "\n",
        "\n",
        "        numeric_columns = [\"Critic_Score\", \"Critic_Count\", \"User_Score\", \"User_Count\"]\n",
        "        imputer = KNNImputer(n_neighbors=5)\n",
        "        df[numeric_columns] = imputer.fit_transform(df[numeric_columns])\n",
        "\n",
        "        return df\n",
        "\n",
        "    df = load_data()\n",
        "\n",
        "    selected_year_range = st.sidebar.slider(\n",
        "        \"Select Year Range\",\n",
        "        min_value=int(df['Year_of_Release'].min()),\n",
        "        max_value=int(df['Year_of_Release'].max()),\n",
        "        value=(2000, 2016)\n",
        "    )\n",
        "\n",
        "    selected_genres = st.sidebar.multiselect(\n",
        "        \"Select Genres\",\n",
        "        options=df['Genre'].unique(),\n",
        "        default=['Action', 'Sports', 'Shooter']\n",
        "    )\n",
        "\n",
        "    st.title(\"Data Story on Gaming 🎮\")\n",
        "    st.header(\" 💲 Video Game Sales\")\n",
        "    st.markdown('<div class=\"fade-in\">', unsafe_allow_html=True)\n",
        "\n",
        "    filtered_df = df[\n",
        "        (df['Year_of_Release'].between(*selected_year_range)) &\n",
        "        (df['Genre'].isin(selected_genres))\n",
        "    ]\n",
        "\n",
        "\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    with col1:\n",
        "        st.metric(\"Total Games Analyzed\", len(filtered_df))\n",
        "    with col2:\n",
        "        st.metric(\"Total Global Sales\", f\"${filtered_df['Global_Sales'].sum():,.1f}B\")\n",
        "    with col3:\n",
        "        st.metric(\"Average Critic Score\", f\"{filtered_df['Critic_Score'].mean():.1f}/100\")\n",
        "\n",
        "\n",
        "    tab1, tab2, tab3, tab4, tab5 = st.tabs([\n",
        "        \"📊 Sales Analysis\",\n",
        "        \"🌟 Score Correlations\",\n",
        "        \"🌍 Regional Insights\",\n",
        "        \"🎮 Game Clusters\",\n",
        "        \"📝 References\"\n",
        "    ])\n",
        "\n",
        "    with tab1:\n",
        "        st.header(\"Sales Performance Analysis\")\n",
        "\n",
        "\n",
        "        num_games = st.slider(\"Select Number of Top Games\", 5, 20, 10)\n",
        "        top_games = filtered_df.nlargest(num_games, 'Global_Sales')\n",
        "\n",
        "        fig = px.bar(top_games,\n",
        "                    x='Global_Sales',\n",
        "                    y='Name',\n",
        "                    orientation='h',\n",
        "                    color='Platform',\n",
        "                    title=f\"Top {num_games} Best-Selling Games\",\n",
        "                    labels={'Global_Sales': 'Global Sales (Millions)'})\n",
        "        st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "\n",
        "        st.subheader(\"Sales Trends Over Time\")\n",
        "        trend_data = filtered_df.groupby(\"Year_of_Release\")[\"Global_Sales\"].sum().reset_index()\n",
        "        fig = px.area(trend_data,\n",
        "                      x='Year_of_Release',\n",
        "                      y='Global_Sales',\n",
        "                      markers=True,\n",
        "                      title=\"Global Sales Trend Over Time\")\n",
        "        st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "    with tab2:\n",
        "        st.header(\"Review Score Analysis\")\n",
        "\n",
        "\n",
        "        score_type = st.radio(\"Select Score Type\", ['Critic_Score', 'User_Score'])\n",
        "\n",
        "        fig = px.scatter(filtered_df,\n",
        "                        x=score_type,\n",
        "                        y='Global_Sales',\n",
        "                        color='Genre',\n",
        "                        size='Critic_Count',\n",
        "                        hover_name='Name',\n",
        "                        title=f\"{score_type.replace('_', ' ')} vs Global Sales\")\n",
        "        st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "        st.subheader(\"Regional Sales Correlations\")\n",
        "        corr_matrix = filtered_df[['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales']].corr()\n",
        "        fig = px.imshow(corr_matrix,\n",
        "                        text_auto=True,\n",
        "                        color_continuous_scale='Blues',\n",
        "                        title=\"Regional Sales Correlation Heatmap\")\n",
        "        st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "    with tab3:\n",
        "        st.header(\"Regional Market Analysis\")\n",
        "\n",
        "\n",
        "        region = st.selectbox(\"Select Region\", ['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales'])\n",
        "        regional_data = filtered_df.groupby('Genre')[region].sum().reset_index()\n",
        "\n",
        "        fig = px.pie(regional_data,\n",
        "                    names='Genre',\n",
        "                    values=region,\n",
        "                    title=f\"{region.replace('_', ' ')} Distribution by Genre\")\n",
        "        st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "\n",
        "        st.subheader(\"Top Publishers by Region\")\n",
        "        publishers = filtered_df.groupby('Publisher')[['NA_Sales', 'EU_Sales', 'JP_Sales']].sum()\n",
        "        fig = px.bar(publishers.nlargest(5, 'NA_Sales'),\n",
        "                    orientation='h',\n",
        "                    title=\"Top Publishers in North America\")\n",
        "        st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "    with tab4:\n",
        "        st.header(\"Game Clustering Analysis\")\n",
        "\n",
        "\n",
        "        n_clusters = st.slider(\"Select Number of Clusters\", 2, 5, 3)\n",
        "\n",
        "        cluster_df = filtered_df[['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales']].dropna()\n",
        "        scaler = StandardScaler()\n",
        "        scaled_data = scaler.fit_transform(cluster_df)\n",
        "\n",
        "\n",
        "        kmeans = KMeans(n_clusters=n_clusters, n_init=10)\n",
        "        cluster_df['Cluster'] = kmeans.fit_predict(scaled_data)\n",
        "\n",
        "\n",
        "        pca = PCA(n_components=2)\n",
        "        pca_results = pca.fit_transform(scaled_data)\n",
        "        cluster_df['PC1'] = pca_results[:, 0]\n",
        "        cluster_df['PC2'] = pca_results[:, 1]\n",
        "\n",
        "        fig = px.scatter(cluster_df,\n",
        "                        x='PC1',\n",
        "                        y='PC2',\n",
        "                        color='Cluster',\n",
        "                        hover_data=['NA_Sales', 'EU_Sales'],\n",
        "                        title=\"PCA Visualization of Game Clusters\")\n",
        "        st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "        st.subheader(\"Cluster Characteristics\")\n",
        "        profile = cluster_df.groupby('Cluster').mean()\n",
        "        st.dataframe(profile.style.background_gradient(cmap='Blues'), use_container_width=True)\n",
        "\n",
        "    st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "    with tab5:\n",
        "\n",
        "        st.header(\"\"\"Thank you\"\"\")\n",
        "        st.header(\"References\")\n",
        "        st.markdown(\"\"\"\n",
        "        - The Gaming sales dataset from [Kaggle Dataset](https://www.kaggle.com/datasets/gregorut/videogamesales)\n",
        "\n",
        "        - The Gaming Psychological dataset from Open Science Framework (https://osf.io/vnbxk/)\n",
        "\n",
        "        \"\"\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoQ5V0obfuyt",
        "outputId": "30edcda8-0438-46b4-e25f-a7ffe9776b60"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "RTtszis0BSLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.set_auth_token(\"2Z2OwWheOVA9BCe2FBstfdc9NTt_3FnAyeXY2cqFZ3x54WeAv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Mu6YYK6BSLm",
        "outputId": "8ce04e56-6e13-4711-d2cd-2fd2bc13bae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup streamlit run app.py &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71287f83-dc39-430a-a326-7b83a294c603",
        "id": "bUBtYHzCBSLm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "public_url = ngrok.connect(8501)\n",
        "print(public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4013e2de-98b6-4c81-f227-2782a9f89863",
        "id": "oicfpKmfBSLm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NgrokTunnel: \"https://cb74-104-198-1-110.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}